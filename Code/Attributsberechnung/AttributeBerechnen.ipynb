{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fe7a80-411d-4475-8832-c4f94548ee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importieren der erforderlichen Bibliotheken\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.sql.functions import col, isnan\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27abc4e-5c7d-4bab-89fc-e4a684bc4c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SparkSession initialisieren und Speicher konfigurieren\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"RecommenderSystem\") \\\n",
    "    .config(\"spark.driver.memory\", \"32g\") \\\n",
    "    .config(\"spark.executor.memory\", \"32g\") \\\n",
    "    .config(\"spark.executor.instances\", \"8\") \\\n",
    "    .config(\"spark.executor.cores\", \"4\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
    "    .config(\"spark.memory.fraction\", \"0.75\") \\\n",
    "    .config(\"spark.executor.heartbeatInterval\", \"30s\") \\\n",
    "    .config(\"spark.network.timeout\", \"300s\") \\\n",
    "    .config(\"spark.sql.pivotMaxValues\", \"80000000\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc3c096-d452-4bfe-9f5c-1af03ca5f2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benutzereingaben für Datensatz, Angriffstyp und Angriffsgröße\n",
    "datensatz = input(\"Bitte den Datensatznamen eingeben: \")\n",
    "angriffstyp = input(\"Bitte den Angriffstyp eingeben: \")\n",
    "angriffsgröße = input(\"Bitte die Angriffsgröße eingeben: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625860c3-c201-4587-9f27-5c06a8ebdd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten einlesen (CSV-Datei mit den entsprechenden Parametern)\n",
    "dateipfad = f\"all_ratings_{datensatz}_{angriffstyp}_{angriffsgröße}.csv\"\n",
    "df = spark.read.csv(dateipfad, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f18ad7-d473-4809-b6b3-89b36a6fb6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b987fe54-2765-4f20-a5ea-bb565a364011",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Umbenennung der Item-Spalte in movieId -> Items werden der Einfachheit wegen konstant als Movies bezeichnet; Führe nur aus bei BookCrossing Datensatz\n",
    "df = df.withColumnRenamed(\"ISBN\", \"movieId\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f0894b-0347-4601-a7c8-12c7ebc33940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Umbenennung der Item-Spalte in movieId -> Items werden der Einfachheit wegen konstant als Movies bezeichnet; Führe nur aus bei Yelp Datensatz\n",
    "df = df.withColumnRenamed(\"businessId\", \"movieId\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d273ee-9ffd-4d67-8f9d-647a9eca2d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung der Durchschnittsbewertungen und RatingCount für jeden Film\n",
    "movie_mean = df.groupBy(\"movieId\").agg(\n",
    "    F.avg(\"rating\").alias(\"RatingMean\"),\n",
    "    F.count(\"rating\").alias(\"RatingCount\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24281484-83ed-4c03-94c0-f2210d6743ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Berechnung von RDMA und WDMA\n",
    "def calculate_RDMA_WDMA(df, movie_mean):\n",
    "    # Join der Filmbewertungen mit dem Durchschnitt und der Anzahl der Bewertungen pro Film\n",
    "    df_with_mean = df.join(movie_mean, on=\"movieId\")\n",
    "    \n",
    "    # Berechnung von RDMA und WDMA pro Film-Bewertung\n",
    "    df_with_rdma = df_with_mean.withColumn(\n",
    "        \"RDMA\",\n",
    "        F.abs(F.col(\"rating\") - F.col(\"RatingMean\")) / F.col(\"RatingCount\")\n",
    "    )\n",
    "\n",
    "    df_with_wdma = df_with_rdma.withColumn(\n",
    "        \"WDMA\",\n",
    "        F.abs(F.col(\"rating\") - F.col(\"RatingMean\")) / (F.col(\"RatingCount\") ** 2)\n",
    "    )\n",
    "    \n",
    "    return df_with_wdma\n",
    "\n",
    "# Anwendung der Berechnungen\n",
    "df_rdma_wdma = calculate_RDMA_WDMA(df, movie_mean)\n",
    "\n",
    "# Aggregation auf Benutzerebene\n",
    "user_profiles = df_rdma_wdma.groupBy(\"userId\").agg(\n",
    "    F.first(\"Label\").alias(\"Label\"),  # Behalte das Label bei\n",
    "    F.sum(\"RDMA\").alias(\"RDMA_sum\"),  # Summe der RDMA-Werte für alle bewerteten Filme\n",
    "    F.sum(\"WDMA\").alias(\"WDMA_sum\"),  # Summe der WDMA-Werte für alle bewerteten Filme\n",
    "    F.count(\"movieId\").alias(\"NumRatings\")  # Anzahl der bewerteten Filme pro Benutzer\n",
    ")\n",
    "\n",
    "# Berechnung des Durchschnitts für RDMA und WDMA\n",
    "user_profiles = user_profiles.withColumn(\n",
    "    \"RDMA\", F.col(\"RDMA_sum\") / F.col(\"NumRatings\")  # Durchschnittlicher RDMA\n",
    ").withColumn(\n",
    "    \"WDMA\", F.col(\"WDMA_sum\") / F.col(\"NumRatings\")  # Durchschnittlicher WDMA\n",
    ").drop(\"RDMA_sum\", \"WDMA_sum\")  # Entferne die Zwischensummen, um die Ausgabe sauber zu halten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944976a5-5a59-425a-a2c6-e179111c92f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Berechnung der durchschnittlichen Profillänge\n",
    "avg_profile_length = df_rdma_wdma.groupBy(\"userId\").agg(F.count(\"movieId\").alias(\"NumRatings\")) \\\n",
    "    .agg(F.avg(\"NumRatings\").alias(\"AvgProfileLength\")).collect()[0][0]\n",
    "\n",
    "# 2. Berechnung der Profillängen für jeden Benutzer\n",
    "user_profile_lengths = df_rdma_wdma.groupBy(\"userId\").agg(F.count(\"movieId\").alias(\"ProfileLength\"))\n",
    "\n",
    "# 3. Berechnung der quadrierten Differenzen zur durchschnittlichen Profillänge\n",
    "length_variance_df = user_profile_lengths.withColumn(\n",
    "    \"SquaredDifference\",\n",
    "    (F.col(\"ProfileLength\") - avg_profile_length) ** 2\n",
    ")\n",
    "\n",
    "# 4. Berechnung des Nenners (Summe der quadrierten Differenzen)\n",
    "denominator = length_variance_df.agg(F.sum(\"SquaredDifference\")).collect()[0][0]\n",
    "\n",
    "# 5. Berechnung von LengthVariance für jeden Benutzer\n",
    "user_profiles = user_profiles.join(user_profile_lengths, on=\"userId\") \\\n",
    "    .withColumn(\n",
    "        \"LengthVariance\",\n",
    "        F.abs(F.col(\"ProfileLength\") - avg_profile_length) / denominator\n",
    "    ).drop(\"ProfileLength\")  # Entferne die ProfileLength Spalte, um Mehrdeutigkeit zu vermeiden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d76bfad-684d-4ad6-91f2-fe3b9208a1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Berechne den Durchschnitt der Bewertungen für jeden Nutzer\n",
    "ratings_self = df.withColumnRenamed(\"userId\", \"user1\").withColumnRenamed(\"rating\", \"rating1\")\n",
    "ratings_other = df.withColumnRenamed(\"userId\", \"user2\").withColumnRenamed(\"rating\", \"rating2\")\n",
    "\n",
    "# 2. Join: Paarbildung basierend auf gemeinsamen Filmen\n",
    "paired_ratings = ratings_self.join(\n",
    "    ratings_other,\n",
    "    (ratings_self.movieId == ratings_other.movieId) & (ratings_self.user1 < ratings_other.user2)\n",
    ")\n",
    "\n",
    "# 3. Durchschnittsbewertungen der Nutzer berechnen\n",
    "user_avg_ratings = df.groupBy(\"userId\").agg(F.avg(\"rating\").alias(\"avg_rating\"))\n",
    "\n",
    "# 4. Join mit den Durchschnittswerten\n",
    "paired_ratings = paired_ratings.join(\n",
    "    user_avg_ratings.withColumnRenamed(\"userId\", \"user1\").withColumnRenamed(\"avg_rating\", \"avg_rating1\"),\n",
    "    \"user1\"\n",
    ").join(\n",
    "    user_avg_ratings.withColumnRenamed(\"userId\", \"user2\").withColumnRenamed(\"avg_rating\", \"avg_rating2\"),\n",
    "    \"user2\"\n",
    ")\n",
    "\n",
    "# 5. Berechne Zähler (Summe der Produkte der Abweichungen der Bewertungen)\n",
    "paired_ratings = paired_ratings.withColumn(\n",
    "    \"numerator\",\n",
    "    (paired_ratings[\"rating1\"] - paired_ratings[\"avg_rating1\"]) * \n",
    "    (paired_ratings[\"rating2\"] - paired_ratings[\"avg_rating2\"])\n",
    ")\n",
    "\n",
    "# 6. Berechne Nenner (Produkt der Wurzeln der quadratischen Abweichungen)\n",
    "paired_ratings = paired_ratings.withColumn(\n",
    "    \"denominator\",\n",
    "    F.sqrt(\n",
    "        F.pow(paired_ratings[\"rating1\"] - paired_ratings[\"avg_rating1\"], 2) *\n",
    "        F.pow(paired_ratings[\"rating2\"] - paired_ratings[\"avg_rating2\"], 2)\n",
    "    )\n",
    ")\n",
    "\n",
    "# 7. Berechne Ähnlichkeit (inkl. negativer Werte)\n",
    "correlations = paired_ratings.withColumn(\n",
    "    \"similarity\",\n",
    "    F.when(paired_ratings[\"denominator\"] != 0, paired_ratings[\"numerator\"] / paired_ratings[\"denominator\"]).otherwise(0)\n",
    ")\n",
    "\n",
    "# 8. Finde die Top-10-Nachbarn basierend auf Ähnlichkeit\n",
    "window_spec = Window.partitionBy(\"user1\").orderBy(F.col(\"similarity\").desc())\n",
    "top_neighbors = correlations.withColumn(\"rank\", F.row_number().over(window_spec)).filter(F.col(\"rank\") <= 10)\n",
    "\n",
    "# 9. Berechne DegSim für jeden Nutzer basierend auf den Top-10-Nachbarn\n",
    "deg_sim = top_neighbors.groupBy(\"user1\").agg(F.avg(\"similarity\").alias(\"DegSim\"))\n",
    "\n",
    "# 10. Join mit dem bestehenden user_profiles DataFrame\n",
    "# Stelle sicher, dass beide DataFrames eine Spalte 'userId' haben.\n",
    "user_profiles = user_profiles.join(deg_sim, user_profiles.userId == deg_sim.user1, \"left_outer\") \\\n",
    "                             .drop(\"user1\") \\\n",
    "                             .fillna({\"DegSim\": 0.0})  # Falls ein Nutzer keinen DegSim hat, setze auf 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58c98cf-708c-4b4a-928a-beb1f58f3a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zeige die Top-Nachbarn\n",
    "top_neighbors.show()\n",
    "\n",
    "# Anzahl der Nachbarn pro Nutzer\n",
    "top_neighbors.groupBy(\"user1\").count().show()\n",
    "\n",
    "user_profiles.groupBy(\"DegSim\").count().show()\n",
    "\n",
    "# Häufigkeiten der DegSim-Werte\n",
    "user_profiles.groupBy(\"DegSim\").count().orderBy(\"DegSim\").show()\n",
    "\n",
    "# Zähle die Anzahl der verschiedenen DegSim-Werte\n",
    "unique_deg_sim_count = user_profiles.select(\"DegSim\").distinct().count()\n",
    "\n",
    "print(f\"Anzahl der verschiedenen DegSim-Werte: {unique_deg_sim_count}\")\n",
    "\n",
    "user_profiles.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec3b70e-eb37-4844-bdc0-dfaeab09bb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zeige das Schema von user_profiles\n",
    "user_profiles.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af83dcc6-073a-481a-8135-8f2ef5549e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 1: Berechnung der maximalen Bewertungen (Target-Items) pro Benutzer\n",
    "user_max_ratings = df.groupBy(\"userId\").agg(F.max(\"rating\").alias(\"MaxRating\"))\n",
    "\n",
    "# Schritt 2: Berechnung der globalen Durchschnittsbewertungen für jedes Item (movieId)\n",
    "global_avg_ratings = df.groupBy(\"movieId\").agg(F.avg(\"rating\").alias(\"GlobalAvgRating\"))\n",
    "\n",
    "# Schritt 3: Berechnung der Target-Items (Items mit MaxRating)\n",
    "user_target_ratings = df.join(user_max_ratings, on=\"userId\") \\\n",
    "    .filter(F.col(\"rating\") == F.col(\"MaxRating\")) \\\n",
    "    .groupBy(\"userId\") \\\n",
    "    .agg(F.collect_list(\"rating\").alias(\"TargetRatings\"))\n",
    "\n",
    "# Schritt 4: Filler-Items berechnen (Bewertungen niedriger als MaxRating)\n",
    "user_filler_ratings_with_id = df.join(user_max_ratings, on=\"userId\") \\\n",
    "    .withColumn(\"is_lower\", F.col(\"rating\") < F.col(\"MaxRating\")) \\\n",
    "    .filter(F.col(\"is_lower\")) \\\n",
    "    .groupBy(\"userId\", \"movieId\") \\\n",
    "    .agg(F.collect_list(\"rating\").alias(\"FillerRatings\"))\n",
    "\n",
    "# Schritt 5: Benutzer finden, die keine Bewertungen niedriger als MaxRating haben\n",
    "users_with_no_lower_ratings = df.join(user_max_ratings, on=\"userId\") \\\n",
    "    .withColumn(\"is_lower\", F.col(\"rating\") < F.col(\"MaxRating\")) \\\n",
    "    .groupBy(\"userId\") \\\n",
    "    .agg(F.sum(F.when(F.col(\"is_lower\"), 1).otherwise(0)).alias(\"lower_count\")) \\\n",
    "    .filter(F.col(\"lower_count\") == 0) \\\n",
    "    .select(\"userId\")\n",
    "\n",
    "# Schritt 6: Filler-Ratings mit MaxRating als Fallback für Benutzer ohne niedrigere Bewertungen\n",
    "user_filler_ratings_with_id_fallback = df.join(user_max_ratings, on=\"userId\") \\\n",
    "    .join(users_with_no_lower_ratings, on=\"userId\", how=\"inner\") \\\n",
    "    .withColumn(\"is_max\", F.col(\"rating\") == F.col(\"MaxRating\")) \\\n",
    "    .filter(F.col(\"is_max\")) \\\n",
    "    .groupBy(\"userId\", \"movieId\") \\\n",
    "    .agg(F.collect_list(\"rating\").alias(\"FillerRatings\"))\n",
    "\n",
    "# Schritt 7: Zusammenführen der Filler-Ratings mit Fallback\n",
    "user_filler_ratings_with_id = user_filler_ratings_with_id.unionByName(user_filler_ratings_with_id_fallback)\n",
    "\n",
    "# Schritt 8: Berechnung der MeanVar (Abweichung von GlobalAvgRating)\n",
    "user_filler_with_global_avg = user_filler_ratings_with_id.join(global_avg_ratings, on=\"movieId\", how=\"left\").withColumn(\n",
    "    \"SquaredDifference\",\n",
    "    F.expr(\"transform(FillerRatings, x -> POWER(x - GlobalAvgRating, 2))\")\n",
    ")\n",
    "\n",
    "mean_var_per_user = user_filler_with_global_avg.groupBy(\"userId\").agg(\n",
    "    F.sum(F.expr(\"aggregate(SquaredDifference, 0D, (acc, x) -> acc + x)\")).alias(\"TotalSquaredDifference\"),\n",
    "    F.sum(F.size(\"FillerRatings\")).alias(\"TotalFillerRatingsCount\")\n",
    ").withColumn(\n",
    "    \"MeanVar\",\n",
    "    F.col(\"TotalSquaredDifference\") / F.col(\"TotalFillerRatingsCount\")\n",
    ").select(\"userId\", \"MeanVar\")\n",
    "\n",
    "# Schritt 9: Berechnung des Zählers und Nenners für FAC\n",
    "fac_numerator = user_filler_with_global_avg.groupBy(\"userId\").agg(\n",
    "    F.sum(F.expr(\"aggregate(FillerRatings, 0D, (acc, x) -> acc + x - GlobalAvgRating)\")).alias(\"FACNumerator\")\n",
    ")\n",
    "\n",
    "fac_denominator = user_filler_with_global_avg.groupBy(\"userId\").agg(\n",
    "    F.sqrt(F.sum(F.expr(\"aggregate(SquaredDifference, 0D, (acc, x) -> acc + x)\"))).alias(\"FACDenominator\")\n",
    ")\n",
    "\n",
    "fac_per_user = fac_numerator.join(fac_denominator, on=\"userId\").withColumn(\n",
    "    \"FAC\",\n",
    "    F.when(F.col(\"FACDenominator\") != 0, F.col(\"FACNumerator\") / F.col(\"FACDenominator\")).otherwise(0)\n",
    ").fillna({\"FAC\": 0}).select(\"userId\", \"FAC\")  # Falls FAC NULL ist, setze 0\n",
    "\n",
    "# Schritt 10: Berechnung des globalen Mittelwerts des Systems für FMD\n",
    "global_mean = df.select(F.avg(\"rating\").alias(\"GlobalMean\")).collect()[0][\"GlobalMean\"]\n",
    "\n",
    "# Schritt 11: Berechnung der absoluten Differenz zur globalen Durchschnittsbewertung für FMD\n",
    "fmd_per_user = user_filler_ratings_with_id.groupBy(\"userId\").agg(\n",
    "    F.avg(F.expr(f\"aggregate(transform(FillerRatings, x -> ABS(x - {global_mean})), 0D, (acc, x) -> acc + x)\")).alias(\"FMD\")\n",
    ")\n",
    "\n",
    "# Schritt 12: Berechnung von FMTD (Target Mean - Filler Mean)\n",
    "# Zunächst werden die Target- und Filler-Ratings explodiert\n",
    "user_filler_ratings_exploded = user_filler_ratings_with_id.withColumn(\"FillerRating\", F.explode(\"FillerRatings\"))\n",
    "user_target_ratings_exploded = user_target_ratings.withColumn(\"TargetRating\", F.explode(\"TargetRatings\"))\n",
    "\n",
    "# Gruppieren nach userId und Berechnen des Mittelwerts für beide Gruppen\n",
    "fmt_per_user = user_target_ratings_exploded.groupBy(\"userId\").agg(\n",
    "    F.avg(\"TargetRating\").alias(\"TargetMean\")\n",
    ").join(\n",
    "    user_filler_ratings_exploded.groupBy(\"userId\").agg(\n",
    "        F.avg(\"FillerRating\").alias(\"FillerMean\")\n",
    "    ),\n",
    "    on=\"userId\",\n",
    "    how=\"inner\"\n",
    ").withColumn(\n",
    "    \"FMTD\",\n",
    "    F.abs(F.col(\"TargetMean\") - F.col(\"FillerMean\"))\n",
    ").select(\"userId\", \"FMTD\")\n",
    "\n",
    "\n",
    "# Schritt 13: Zusammenführen aller Maße ins Benutzerprofil\n",
    "user_profiles = user_profiles.join(mean_var_per_user, on=\"userId\", how=\"left\") \\\n",
    "    .join(fac_per_user, on=\"userId\", how=\"left\") \\\n",
    "    .join(fmd_per_user, on=\"userId\", how=\"left\") \\\n",
    "    .join(fmt_per_user, on=\"userId\", how=\"left\")\n",
    "\n",
    "# Schritt 14: Sicherstellen, dass `user_profiles` eindeutig pro Benutzer ist durch Entfernung eventueller Duplikate\n",
    "user_profiles = user_profiles.dropDuplicates([\"userId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447e6d90-97bc-46bc-a0f1-92660ee9a0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nicht mehr benötigte Spalten entfernen\n",
    "user_profiles = user_profiles.drop(\"NumRatings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab13791-860c-48fb-94f1-60c9bd2f7188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zeige erneut das Schema von user_profiles\n",
    "user_profiles.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ae710f-b6f0-4ebc-8e40-6229852b2972",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ausgabe des finalen DataFrames\n",
    "user_profiles.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301f2586-477a-44af-ad38-b421f365f1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runden der Werte und Umwandlung in String, um wissenschaftliche Notation zu vermeiden\n",
    "user_profiles = user_profiles.withColumn(\"RDMA\", F.format_number(F.round(\"RDMA\", 10), 10)) \\\n",
    "                             .withColumn(\"WDMA\", F.format_number(F.round(\"WDMA\", 10), 10)) \\\n",
    "                             .withColumn(\"LengthVariance\", F.format_number(F.round(\"LengthVariance\", 10), 10)) \\\n",
    "                             .withColumn(\"MeanVar\", F.format_number(F.round(\"MeanVar\", 10), 10)) \\\n",
    "                             .withColumn(\"FMTD\", F.format_number(F.round(\"FMTD\", 10), 10)) \\\n",
    "                             .withColumn(\"FAC\", F.format_number(F.round(\"FAC\", 10), 10)) \\\n",
    "                             .withColumn(\"FMD\", F.format_number(F.round(\"FMD\", 10), 10)) \\\n",
    "                             .withColumn(\"DegSim\", F.format_number(F.round(\"DegSim\", 10), 10))\n",
    "\n",
    "# Sortieren nach userId\n",
    "user_profiles = user_profiles.orderBy(\"userId\", ascending=True)\n",
    "\n",
    "# Ausgabe des finalen DataFrames\n",
    "user_profiles.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b610d3-5784-4757-8c19-cfa241a12f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Letzte 20 UserIDs anzeigen\n",
    "last_20_users = user_profiles.orderBy(F.col(\"UserID\").desc()).limit(20)\n",
    "last_20_users.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f149bea5-8280-463e-a351-535cb8e90d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamische Bedingung für alle Spalten im DataFrame `user_profiles`\n",
    "nan_or_null_filter = [isnan(col(c)) | col(c).isNull() for c in user_profiles.columns]\n",
    "user_profiles_nan = user_profiles.filter(reduce(lambda x, y: x | y, nan_or_null_filter))\n",
    "\n",
    "# Zeige die Zeilen mit mindestens einem NaN oder NULL-Wert\n",
    "user_profiles_nan.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b00580a-7e98-4dc4-a7e2-4213425e61d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Anzahl der NaN- oder Null- Zeilen im gesamten DataFrame\n",
    "total_rows_nan = user_profiles_nan.count()\n",
    "print(f\"Gesamtanzahl der NaN-Zeilen: {total_rows_nan}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c6fd16-f805-497d-8c18-27ea57e84ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzahl der Zeilen im gesamten DataFrame\n",
    "total_rows = user_profiles.count()\n",
    "print(f\"Gesamtanzahl der Zeilen: {total_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b2a3e0-0997-4224-92f8-d94231fe22b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dateinamen erstellen (Basierend auf den Benutzereingaben)\n",
    "dateiname = f\"ratings_readyforclassification_{datensatz}_{angriffstyp}_{angriffsgröße}_Ordner.csv\"\n",
    "\n",
    "# DataFrame als CSV speichern\n",
    "user_profiles.coalesce(1).write.csv(dateiname, header=True)\n",
    "\n",
    "print(f\"DataFrame wurde als {dateiname} gespeichert.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a10e5e-1224-42de-9ab4-6295aee746c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beende die Spark-Session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
