{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ddb5cb-483d-488e-bb63-afc802e2021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importieren der erforderlichen Bibliotheken\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    col, expr, size, array_intersect, percent_rank, abs\n",
    ")\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb7db47-bbf3-4937-bcb5-702e93cc42c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark Session initialisieren\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MovieLens_ALS\") \\\n",
    "    .config(\"spark.driver.memory\", \"16g\") \\\n",
    "    .config(\"spark.executor.memory\", \"16g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe3305d-ddee-464a-b9cb-1c7e737ffccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einlesen des Ratings-Datensatzes\n",
    "ratings1 = spark.read.csv(\"ml-32m/ratings.csv\", header=True, inferSchema=True)\n",
    "ratings1 = ratings1.dropna().dropDuplicates()\n",
    "\n",
    "# Da in diesem Datensatz die Spalten bereits \"userId\" und \"movieId\" heißen,\n",
    "# werden sie umbenannt, um sie später mit Datensatz 2 zusammenführen zu können.\n",
    "ratings1 = ratings1.withColumnRenamed(\"userId\", \"userId_orig\") \\\n",
    "                   .withColumnRenamed(\"movieId\", \"movieId_orig\")\n",
    "# Die Spalte \"rating\" wird unverändert verwendet (als numerischen Wert)\n",
    "# Entferne die Spalte \"timestamp\", da sie nicht benötigt wird.\n",
    "ratings1 = ratings1.drop(\"timestamp\")\n",
    "# Zeige 20 Einträge aus Datensatz 1\n",
    "ratings1.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75cda52-27e6-4b3c-8d10-1f11f627282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einlesen des Datensatzes nach Angriff (tausche Angriffsart und Angriffsgröße jeweils aus)\n",
    "ratings2 = spark.read.option(\"header\", \"true\").csv(\"all_ratings_MovieLens32M_reverse_bandwagon_20.0.csv\")\n",
    "# Entferne fehlende Werte und Duplikate\n",
    "ratings2 = ratings2.dropna().dropDuplicates()\n",
    "\n",
    "# Benenne auch hier die Nutzer- und Item-Spalten in einen gemeinsamen Namensraum um.\n",
    "ratings2 = ratings2.withColumnRenamed(\"userId\", \"userId_orig\") \\\n",
    "                   .withColumnRenamed(\"movieId\", \"movieId_orig\")\n",
    "# Stelle sicher, dass \"rating\" als Float vorliegt:\n",
    "ratings2 = ratings2.withColumn(\"rating\", col(\"rating\").cast(\"float\"))\n",
    "# Entferne nicht benötigte Spalten\n",
    "ratings2 = ratings2.drop(\"timestamp\")\n",
    "ratings2 = ratings2.drop(\"Label\")\n",
    "# Zeige 20 Einträge aus Datensatz 2\n",
    "ratings2.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa656a2e-b452-4fd1-bb09-191b50e726df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kombiniere alle eindeutigen Nutzer-IDs aus beiden Datensätzen\n",
    "combined_users = ratings1.select(\"userId_orig\").union(ratings2.select(\"userId_orig\")).distinct()\n",
    "user_indexer = StringIndexer(inputCol=\"userId_orig\", outputCol=\"userId\", handleInvalid=\"skip\")\n",
    "user_indexer_model = user_indexer.fit(combined_users)\n",
    "\n",
    "# Wende den gleichen Nutzer-Indexer auf beide Datensätze an\n",
    "ratings1 = user_indexer_model.transform(ratings1)\n",
    "ratings2 = user_indexer_model.transform(ratings2)\n",
    "\n",
    "# Erzeuge einen DataFrame aller eindeutigen Items (Movies) aus beiden Datensätzen\n",
    "combined_movies = ratings1.select(\"movieId_orig\").union(ratings2.select(\"movieId_orig\")).distinct()\n",
    "movie_indexer = StringIndexer(inputCol=\"movieId_orig\", outputCol=\"movieId_new\", handleInvalid=\"skip\")\n",
    "movie_indexer_model = movie_indexer.fit(combined_movies)\n",
    "\n",
    "# Wende den Item-Indexer auf beide Datensätze an\n",
    "ratings1 = movie_indexer_model.transform(ratings1)\n",
    "ratings2 = movie_indexer_model.transform(ratings2)\n",
    "\n",
    "# Entferne die Originalspalten, da ausschließlich mit den indexierten Spalten weitergearbeitet wird\n",
    "ratings1 = ratings1.drop(\"userId_orig\", \"movieId_orig\")\n",
    "ratings2 = ratings2.drop(\"userId_orig\", \"movieId_orig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba196e0f-2ef6-4a83-8630-30501fe5f32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teile die Daten in Trainings- und Testdaten auf in einem 80/20-Verhältnis\n",
    "train1, test1 = ratings1.randomSplit([0.8, 0.2], seed=42)\n",
    "print(f\"Datensatz 1: Trainingsset: {train1.count()} Einträge, Testset: {test1.count()} Einträge\")\n",
    "\n",
    "train2, test2 = ratings2.randomSplit([0.8, 0.2], seed=42)\n",
    "print(f\"Datensatz 2: Trainingsset: {train2.count()} Einträge, Testset: {test2.count()} Einträge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658ec515-1aae-48a8-b5cd-873b83f257cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALS-Algorithmus für Datensatz 1 (vor Angriff)\n",
    "als1 = ALS(\n",
    "    rank=100,\n",
    "    maxIter=20,\n",
    "    regParam=0.05,\n",
    "    userCol=\"userId\",\n",
    "    itemCol=\"movieId_new\",\n",
    "    ratingCol=\"rating\",\n",
    "    coldStartStrategy=\"drop\"\n",
    ")\n",
    "als_model1 = als1.fit(train1)\n",
    "predictions1 = als_model1.transform(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cc3db2-eed5-41bb-b8af-91db06f66de7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RMSE und MAE für Datensatz 1 berechnen\n",
    "evaluator_rmse1 = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "evaluator_mae1 = RegressionEvaluator(metricName=\"mae\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "rmse1 = evaluator_rmse1.evaluate(predictions1)\n",
    "mae1 = evaluator_mae1.evaluate(predictions1)\n",
    "\n",
    "print(f\"Datensatz 1 - RMSE: {rmse1}\")\n",
    "print(f\"Datensatz 1 - MAE: {mae1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5971bb-dfab-4e0f-b323-79e36d439f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HitRate-Berechnung für Datensatz 1\n",
    "window_spec1 = Window.orderBy(col(\"rating\").desc())\n",
    "test1 = test1.withColumn(\"percentile\", percent_rank().over(window_spec1))\n",
    "# Verwende die besten 20% der Bewertungen als relevante Items und gruppiere nach userId\n",
    "relevant_items1 = test1.filter(col(\"percentile\") <= 0.2) \\\n",
    "                       .groupBy(\"userId\") \\\n",
    "                       .agg(expr(\"collect_list(movieId_new) as relevant_items\"))\n",
    "\n",
    "# Verwende 10 und 20 als Werte für k, um die HitRate@10 sowie HitRate@20 zu berechnen\n",
    "k_values = [10, 20]\n",
    "for k in k_values:\n",
    "    top_k_recommendations1 = als_model1.recommendForAllUsers(k)\n",
    "    top_k_recommendations_exploded1 = top_k_recommendations1.withColumn(\n",
    "        \"recommended_item_ids\",\n",
    "        expr(\"transform(recommendations, x -> x['movieId_new'])\")\n",
    "    )\n",
    "    joined_data1 = top_k_recommendations_exploded1.join(relevant_items1, on=\"userId\", how=\"inner\")\n",
    "    hit_data1 = joined_data1.withColumn(\n",
    "        \"relevant_in_recommendations\",\n",
    "        size(array_intersect(col(\"recommended_item_ids\"), col(\"relevant_items\")))\n",
    "    )\n",
    "    hit_data1 = hit_data1.withColumn(\"is_hit\", col(\"relevant_in_recommendations\") > 0)\n",
    "    count_joined1 = joined_data1.count()\n",
    "# Berechne die durchschnittliche HitRate über alle User\n",
    "    hit_rate1 = hit_data1.filter(col(\"is_hit\") == True).count() / count_joined1 if count_joined1 > 0 else None\n",
    "    print(f\"Datensatz 1 - HitRate@{k}: {hit_rate1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00b09b1-7440-4927-8dc7-0dc3b38d4e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALS-Algorithmus für Datensatz 2 (nach Angriff)\n",
    "als2 = ALS(\n",
    "    rank=100,\n",
    "    maxIter=20,\n",
    "    regParam=0.05,\n",
    "    userCol=\"userId\",\n",
    "    itemCol=\"movieId_new\",\n",
    "    ratingCol=\"rating\",\n",
    "    coldStartStrategy=\"drop\"\n",
    ")\n",
    "als_model2 = als2.fit(train2)\n",
    "predictions2 = als_model2.transform(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd9e085-4e26-4950-859f-2e61efc6d76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE und MAE für Datensatz 2 berechnen\n",
    "evaluator_rmse2 = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "evaluator_mae2 = RegressionEvaluator(metricName=\"mae\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "rmse2 = evaluator_rmse2.evaluate(predictions2)\n",
    "mae2 = evaluator_mae2.evaluate(predictions2)\n",
    "\n",
    "print(f\"Datensatz 2 - RMSE: {rmse2}\")\n",
    "print(f\"Datensatz 2 - MAE: {mae2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb64f7b-cfb9-4928-b254-dfad6cbd8444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HitRate-Berechnung für Datensatz 2\n",
    "window_spec2 = Window.orderBy(col(\"rating\").desc())\n",
    "test2 = test2.withColumn(\"percentile\", percent_rank().over(window_spec2))\n",
    "# Verwende die besten 20% der Bewertungen als relevante Items und gruppiere nach userId\n",
    "relevant_items2 = test2.filter(col(\"percentile\") <= 0.2) \\\n",
    "                       .groupBy(\"userId\") \\\n",
    "                       .agg(expr(\"collect_list(movieId_new) as relevant_items\"))\n",
    "\n",
    "for k in k_values:\n",
    "    top_k_recommendations2 = als_model2.recommendForAllUsers(k)\n",
    "    top_k_recommendations_exploded2 = top_k_recommendations2.withColumn(\n",
    "        \"recommended_item_ids\",\n",
    "        expr(\"transform(recommendations, x -> x['movieId_new'])\")\n",
    "    )\n",
    "    joined_data2 = top_k_recommendations_exploded2.join(relevant_items2, on=\"userId\", how=\"inner\")\n",
    "    hit_data2 = joined_data2.withColumn(\n",
    "        \"relevant_in_recommendations\",\n",
    "        size(array_intersect(col(\"recommended_item_ids\"), col(\"relevant_items\")))\n",
    "    )\n",
    "    hit_data2 = hit_data2.withColumn(\"is_hit\", col(\"relevant_in_recommendations\") > 0)\n",
    "    count_joined2 = joined_data2.count()\n",
    "# Berechne die durchschnittliche HitRate über alle User\n",
    "    hit_rate2 = hit_data2.filter(col(\"is_hit\") == True).count() / count_joined2 if count_joined2 > 0 else None\n",
    "    print(f\"Datensatz 2 - HitRate@{k}: {hit_rate2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6a9cf5-f4db-4ff4-be79-5c82dfe7dbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechne Vorhersagen auf den Trainingsdaten beider Modelle\n",
    "train_predictions1 = als_model1.transform(train1) \\\n",
    "    .select(\"userId\", \"movieId_new\", col(\"prediction\").alias(\"prediction_1\"))\n",
    "train_predictions2 = als_model2.transform(train2) \\\n",
    "    .select(\"userId\", \"movieId_new\", col(\"prediction\").alias(\"prediction_2\"))\n",
    "\n",
    "# Join der Vorhersagen über die gemeinsamen Schlüssel\n",
    "common_predictions = train_predictions1.join(train_predictions2, on=[\"userId\", \"movieId_new\"], how=\"inner\")\n",
    "\n",
    "# Berechne den absoluten Unterschied und den durchschnittlichen Prediction Shift\n",
    "common_predictions = common_predictions.withColumn(\"abs_diff\", abs(col(\"prediction_1\") - col(\"prediction_2\")))\n",
    "prediction_shift = common_predictions.agg({\"abs_diff\": \"avg\"}).collect()[0][0]\n",
    "print(f\"Prediction Shift: {prediction_shift}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecbc7fd-8274-49c9-8edc-16baf1d15c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beende die Spark-Session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
